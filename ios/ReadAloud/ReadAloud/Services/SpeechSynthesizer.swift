import Foundation
import AVFoundation
import Combine

class SpeechSynthesizer: NSObject, ObservableObject, AVSpeechSynthesizerDelegate {
    @Published var isPlaying = false
    @Published var currentPosition: Double = 0.0
    @Published var currentText: String = ""
    
    private var synthesizer = AVSpeechSynthesizer()
    public var fullText: String = ""
    private var utterance: AVSpeechUtterance?
    private var document: Document?
    private var documentViewModel: DocumentsViewModel?
    
    // è¯­éŸ³é€‰é¡¹
    var voice: AVSpeechSynthesisVoice? = AVSpeechSynthesisVoice(language: "zh-CN")
    var rate: Float = AVSpeechUtteranceDefaultSpeechRate
    var volume: Float = 1.0
    var pitchMultiplier: Float = 1.0
    
    override init() {
        super.init()
        synthesizer.delegate = self
        configureAudioSession()
    }
    
    private func configureAudioSession() {
        do {
            // é…ç½®éŸ³é¢‘ä¼šè¯
            let audioSession = AVAudioSession.sharedInstance()
            try audioSession.setCategory(.playback, mode: .spokenAudio, options: [.duckOthers, .allowBluetooth])
            try audioSession.setActive(true, options: .notifyOthersOnDeactivation)
            print("éŸ³é¢‘ä¼šè¯é…ç½®æˆåŠŸ")
        } catch {
            print("éŸ³é¢‘ä¼šè¯é…ç½®å¤±è´¥: \(error.localizedDescription)")
        }
    }
    
    func loadDocument(_ document: Document, viewModel: DocumentsViewModel) {
        self.document = document
        self.documentViewModel = viewModel
        
        // ä½¿ç”¨å¼‚æ­¥å¤„ç†é¿å…é˜»å¡UIçº¿ç¨‹
        DispatchQueue.global(qos: .userInitiated).async { [weak self] in
            guard let self = self else { return }
            
            do {
                let extractedText = try TextExtractor.extractText(from: document)
                
                DispatchQueue.main.async {
                    self.fullText = extractedText
                    
                    // é‡ç½®æœ—è¯»è¿›åº¦
                    self.currentPosition = document.progress
                    
                    // æ›´æ–°å½“å‰æ˜¾ç¤ºçš„æ–‡æœ¬æ®µè½
                    self.updateCurrentTextDisplay()
                }
            } catch let extractionError as TextExtractor.ExtractionError {
                DispatchQueue.main.async {
                    self.currentText = "æ–‡æœ¬æå–å¤±è´¥: \(extractionError.localizedDescription)"
                    print("æ–‡æœ¬æå–å¤±è´¥: \(extractionError)")
                }
            } catch {
                DispatchQueue.main.async {
                    self.currentText = "æ–‡æœ¬æå–å¤±è´¥: \(error.localizedDescription)"
                    print("æ–‡æœ¬æå–å¤±è´¥: \(error)")
                }
            }
        }
    }
    
    public func updateCurrentTextDisplay() {
        // æ ¹æ®å½“å‰è¿›åº¦å®šä½åˆ°æ–‡æœ¬ç›¸åº”ä½ç½®
        if !fullText.isEmpty {
            let startIndex = fullText.index(fullText.startIndex, offsetBy: min(Int(Double(fullText.count) * currentPosition), fullText.count - 1))
            let previewLength = min(500, fullText.count - fullText.distance(from: fullText.startIndex, to: startIndex))
            let endIndex = fullText.index(startIndex, offsetBy: previewLength)
            
            currentText = String(fullText[startIndex..<endIndex])
        }
    }
    
    func startSpeaking(from position: Double? = nil) {
        // åœæ­¢å½“å‰æœ—è¯»
        if synthesizer.isSpeaking {
            synthesizer.stopSpeaking(at: .immediate)
        }
        
        // è®¾ç½®æœ—è¯»ä½ç½®
        if let pos = position {
            currentPosition = pos
        }
        
        // æ£€æŸ¥æ–‡æœ¬æ˜¯å¦ä¸ºç©º
        if fullText.isEmpty {
            print("âš ï¸ æ— æ³•æœ—è¯»ï¼šæ–‡æœ¬ä¸ºç©º")
            return
        }
        
        // æ ¹æ®ä½ç½®è·å–å¼€å§‹æœ—è¯»çš„æ–‡æœ¬
        let startOffset = Int(Double(fullText.count) * currentPosition)
        let textToSpeak = fullText.count > startOffset ? String(fullText[fullText.index(fullText.startIndex, offsetBy: startOffset)...]) : ""
        
        if textToSpeak.isEmpty {
            print("âš ï¸ æ— æ³•æœ—è¯»ï¼šæˆªå–çš„æ–‡æœ¬ä¸ºç©º")
            return
        }
        
        print("ğŸ”Š å¼€å§‹æœ—è¯»ï¼Œæ–‡æœ¬é•¿åº¦: \(textToSpeak.count)ï¼Œèµ·å§‹ä½ç½®: \(currentPosition)")
        
        // åˆ›å»ºæœ—è¯»å¯¹è±¡
        utterance = AVSpeechUtterance(string: textToSpeak)
        
        // è®¾ç½®è¯­éŸ³å’Œå‚æ•°
        if let voice = AVSpeechSynthesisVoice(language: "zh-CN") {
            utterance?.voice = voice
            print("âœ“ è®¾ç½®è¯­éŸ³: \(voice.language)")
        } else {
            print("âš ï¸ æ— æ³•è®¾ç½®ä¸­æ–‡è¯­éŸ³ï¼Œä½¿ç”¨é»˜è®¤è¯­éŸ³")
        }
        
        // è°ƒæ•´å‚æ•°ï¼Œä½¿å£°éŸ³æ›´æ˜æ˜¾
        utterance?.rate = min(max(0.4, rate), 0.6) // è°ƒæ•´é€Ÿç‡åˆ°0.4-0.6ä¹‹é—´
        utterance?.volume = 1.0 // è®¾ç½®æœ€å¤§éŸ³é‡
        utterance?.pitchMultiplier = 1.0 // é»˜è®¤éŸ³è°ƒ
        
        print("âœ“ è¯­éŸ³å‚æ•°: é€Ÿç‡=\(utterance?.rate ?? 0), éŸ³é‡=\(utterance?.volume ?? 0), éŸ³è°ƒ=\(utterance?.pitchMultiplier ?? 0)")
        
        // å¼€å§‹æœ—è¯»
        if let utterance = utterance {
            synthesizer.speak(utterance)
            isPlaying = true
            print("âœ“ å·²å‘é€æœ—è¯»å‘½ä»¤")
        } else {
            print("âš ï¸ åˆ›å»ºæœ—è¯»utteranceå¤±è´¥")
        }
        
        updateCurrentTextDisplay()
    }
    
    func pauseSpeaking() {
        if synthesizer.isSpeaking {
            synthesizer.pauseSpeaking(at: .word)
            isPlaying = false
        }
    }
    
    func resumeSpeaking() {
        if synthesizer.isPaused {
            synthesizer.continueSpeaking()
            isPlaying = true
        } else if !isPlaying && !fullText.isEmpty {
            // å¦‚æœæ²¡æœ‰æš‚åœä½†ä¹Ÿæ²¡æœ‰åœ¨æ’­æ”¾ï¼Œè€Œä¸”æœ‰å†…å®¹ï¼Œåˆ™å¼€å§‹æ’­æ”¾
            startSpeaking(from: currentPosition)
        }
    }
    
    func stopSpeaking() {
        synthesizer.stopSpeaking(at: .immediate)
        isPlaying = false
        
        // ä¿å­˜é˜…è¯»è¿›åº¦
        saveProgress()
    }
    
    func setPlaybackRate(_ rate: Float) {
        self.rate = rate
        // åº”ç”¨åˆ°å½“å‰æœ—è¯»
        if let currentUtterance = utterance {
            currentUtterance.rate = rate
        }
    }
    
    func skipForward() {
        // å‘å‰è·³è¿‡ä¸€å°æ®µ
        currentPosition = min(1.0, currentPosition + 0.01)
        if isPlaying {
            startSpeaking(from: currentPosition)
        } else {
            updateCurrentTextDisplay()
        }
    }
    
    func skipBackward() {
        // å‘åè·³è¿‡ä¸€å°æ®µ
        currentPosition = max(0.0, currentPosition - 0.01)
        if isPlaying {
            startSpeaking(from: currentPosition)
        } else {
            updateCurrentTextDisplay()
        }
    }
    
    func seekTo(position: Double) {
        currentPosition = max(0.0, min(1.0, position))
        if isPlaying {
            startSpeaking(from: currentPosition)
        } else {
            updateCurrentTextDisplay()
        }
    }
    
    private func saveProgress() {
        if let doc = document, let viewModel = documentViewModel {
            viewModel.updateDocumentProgress(id: doc.id, progress: currentPosition)
        }
    }
    
    // MARK: - AVSpeechSynthesizerDelegate
    
    func speechSynthesizer(_ synthesizer: AVSpeechSynthesizer, didStart utterance: AVSpeechUtterance) {
        DispatchQueue.main.async {
            self.isPlaying = true
            print("ï¿½ï¿½ å¼€å§‹æœ—è¯»æ–‡æœ¬")
        }
    }
    
    func speechSynthesizer(_ synthesizer: AVSpeechSynthesizer, didFinish utterance: AVSpeechUtterance) {
        DispatchQueue.main.async {
            self.isPlaying = false
            print("âœ“ æœ—è¯»å®Œæˆ")
            
            // æ ‡è®°ä¸ºå·²å®Œæˆ
            if utterance.speechString == self.fullText {
                self.currentPosition = 1.0
            }
            
            // ä¿å­˜é˜…è¯»è¿›åº¦
            self.saveProgress()
        }
    }
    
    func speechSynthesizer(_ synthesizer: AVSpeechSynthesizer, didPause utterance: AVSpeechUtterance) {
        DispatchQueue.main.async {
            self.isPlaying = false
            print("â¸ æœ—è¯»æš‚åœ")
        }
    }
    
    func speechSynthesizer(_ synthesizer: AVSpeechSynthesizer, didContinue utterance: AVSpeechUtterance) {
        DispatchQueue.main.async {
            self.isPlaying = true
            print("â–¶ï¸ æœ—è¯»ç»§ç»­")
        }
    }
    
    func speechSynthesizer(_ synthesizer: AVSpeechSynthesizer, willSpeakRangeOfSpeechString characterRange: NSRange, utterance: AVSpeechUtterance) {
        DispatchQueue.main.async {
            // æ›´æ–°æœ—è¯»è¿›åº¦
            let progress = Double(characterRange.location) / Double(utterance.speechString.count)
            let overallProgress = self.currentPosition + progress * (1.0 - self.currentPosition)
            
            self.currentPosition = overallProgress
            
            // æ›´æ–°å½“å‰æ˜¾ç¤ºçš„æ–‡æœ¬
            self.updateCurrentTextDisplay()
        }
    }
} 